{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Hidden Markov Model (HMM) is a statistical model that represents a system undergoing a sequence of hidden (latent, unobservable) states. \n",
    "\n",
    "- HMM can be considered an extension of the Naive Bayes classifier to sequences\n",
    "\n",
    "- HMM is a weighted finite-state transducer\n",
    "\n",
    "- sequence of hidden states form a **Markov Chain** because they follow the **Markov assumption**.\n",
    "\n",
    "- hidden states encode most recent history, emit observable symbols (observations) according to specific probability distributions.\n",
    "\n",
    "- observations are sequential data, i.e. sequence of dependent random variables. e.g., text, weather reports, stock market numbers\n",
    "\n",
    "- in POS tagging, hidden states are POS tags and observations are words in text sequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov assumption"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first-order Markov assumption: current hidden state depends only on the previous hidden state and is conditionally independent of earlier hidden states. \n",
    "\n",
    "$$\n",
    "P(q_t|q_{t-1}, ..., q_1)=P(q_t|q_{t-1})\n",
    "$$\n",
    "\n",
    "Where $q_t$ represents the hidden state at time step $t$. This assumption simplifies the modeling of dependencies in the hidden state sequence, making it more computationally tractable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Markov chain is a stochastic process that models a sequence of events.\n",
    "\n",
    "**Markov property**: memoryless property. future state depends only on current state and not on previous states\n",
    "\n",
    "\n",
    "A Markov chain is characterized by:\n",
    "\n",
    "1. A finite set of states: $S = \\{s_1, s_2, \\dots, s_N\\}$\n",
    "\n",
    "2. Transition probabilities: $P = \\{p_{ij}\\}$, where $p_{ij}$ is the probability of transitioning from state $s_i$ to state $s_j$, with $\\sum_{j=1}^N p_{ij} = 1 \\ \\forall i$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other methods that use Markov chain:\n",
    "\n",
    "- Markov Chain Monte Carlo (MCMC) Method: a class of algorithms for sampling from a probability distribution, e.g., Metropolis-Hastings algorithm and Gibbs sampling\n",
    "\n",
    "- Markov Decision Processe (MDP):  in reinforcement learning, The states represent different situations, the transitions represent actions taken by an agent, and the transition probabilities represent the effects of those actions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## definition (parameters of HMM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden Markov model $\\mu=(A, B, \\Pi)$ is defined by initial state probabilities $\\Pi$, state transition probabilities $A$, and symbol emission probabilities $B$.\n",
    "\n",
    "- states $\\mathcal{Q}=\\left\\{q_0, q_1, ..., q_T\\right\\}$: a sequence of T hidden states consists of $N$ finite possible states. \n",
    "\n",
    "    initial state $q_0$ doesn't emit any observation\n",
    "    \n",
    "    final state $q_T$ doesn't transition to any state. \n",
    "\n",
    "- observations $O=\\left\\{o_1, o_2, ..., o_T\\right\\}$: a sequence of $T$ observations, each one drawn from a vocabulary $\\mathcal{V}=\\{v_1, ..., v_{|\\mathcal{V}|}\\}$\n",
    "\n",
    "- state transition probabilities $A \\in \\mathbb{R}^{N \\times N}$: a transition probability matrix.\n",
    "\n",
    "    $A_{ij}$: probability of moving from state $i$ to state $j$. s.t. $\\sum_{j=1}^N A_{ij}=1 \\ \\forall i$\n",
    "\n",
    "- symbol emission probabilities $B =\\left\\{\\phi_i(o_t)\\right\\}\\in \\mathbb{R}^{N \\times |V|}$: an emission probability matrix. \n",
    "\n",
    "    each row is a hidden state, each column is an observation. \n",
    "\n",
    "    $B_{it}$: probability of t-th observation $o_t$ being generated from state $i$ s.t. $\\sum_{t=1}^{|V|} B_{it}=1 \\ \\forall i$\n",
    "\n",
    "\n",
    "- initial state probabilities $\\Pi = \\left\\{\\pi_1, \\pi_2, ..., \\pi_N\\right\\}$: an initial probability distribution over states. \n",
    "\n",
    "    $\\sum_{i=1}^n \\pi_i = 1$, $\\pi_i$ is probability that Markov chain starts in state $i$. \n",
    "    \n",
    "    some states $j$ may have $\\pi_j=0$, meaning that they can't be initial states."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example of POS tagging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "States (POS tags): \n",
    "Q = {q0 (START), Noun (q1), Verb (q2), Adjective (q3), q4 (END)}\n",
    "\n",
    "Vocabulary: \n",
    "V = {v1 (dog), v2 (cat), v3 (ran), v4 (quickly), v5 (jumped), v6 (slowly)}\n",
    "\n",
    "Observations:\n",
    "O = {o1, o2, o3, o4, o5, o6, o7, o8}\n",
    "\n",
    "Transition probabilities A:\n",
    "|        | START | Noun | Verb | Adjective | END |\n",
    "|--------|-------|------|------|-----------|-----|\n",
    "| START  | 0     | 0.2  | 0.3  | 0.5       | 0   |\n",
    "| Noun   | 0     | 0.3  | 0.3  | 0         | 0.4 |\n",
    "| Verb   | 0     | 0    | 0.4  | 0.6       | 0   |\n",
    "| Adjective| 0   | 0.2  | 0    | 0.3       | 0.5 |\n",
    "| END    | 0     | 0    | 0    | 0         | 0   |\n",
    "\n",
    "Emission probabilities B:\n",
    "|        | dog | cat | ran | quickly | jumped | slowly |\n",
    "|--------|-----|-----|-----|---------|--------|--------|\n",
    "| START  | 0   | 0   | 0   | 0       | 0      | 0      |\n",
    "| Noun   | 0.1 | 0.3 | 0.2 | 0.1     | 0.1    | 0.2    |\n",
    "| Verb   | 0.2 | 0.1 | 0.2 | 0.3     | 0.1    | 0.1    |\n",
    "| Adjective| 0.1| 0.1 | 0.2 | 0.2     | 0.2    | 0.2    |\n",
    "| END    | 0   | 0   | 0   | 0       | 0      | 0      |\n",
    "\n",
    "Initial state probabilities $\\Pi$: Adjective can't be initial state\n",
    "| START | Noun | Verb | Adjective | END |\n",
    "|-------|------|------|-----------|-----|\n",
    "| 0.8   | 0.1    | 0.05 | 0       | 0.15|\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Aspect | Forward-Backward | Viterbi | Baum-Welch (EM) |\n",
    "|---|---|---|---|\n",
    "| **Input** | HMM parameters $\\mu=(A, B, \\Pi)$ and Observed sequence $O$ | HMM parameters $\\mu=(A, B, \\Pi)$ and Observed sequence $O$ | Initial guess of HMM parameters $\\mu_0=(A, B, \\Pi)$ and Observed sequence $O$|\n",
    "| **Output** | State probabilities $P(q_t \\| O, \\mu)$ at each time step | Most probable state sequence $\\hat {\\mathcal{Q}}$| estimated HMM parameters  $\\hat \\mu$|\n",
    "| **Algorithm** | Dynamic programming | Dynamic programming | Iterative optimization |\n",
    "| **Applications** | POS tagging, Speech recognition, gene prediction | POS tagging, Speech recognition, Error detection & correction, sequence alignment | Speech recognition, gene prediction |\n",
    "| **Dependencies** | Forward & backward probabilities | Maximum probability of the most likely path | Expectation-maximization approach |\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM generator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generative process of a Hidden Markov Model: generate a sequence of observations and hidden states from a given Hidden Markov Model (HMM) by iteratively sampling from the HMM model probabilities.\n",
    "\n",
    "1. Sample an initial hidden state $q_0$ from the initial state probability distribution $\\Pi$.\n",
    "\n",
    "2. For each time step $t = 1, \\dots, T$:\n",
    "   \n",
    "   a. Move to another state: Based on the current state $q_t$ and the state transition probabilities $A$, sample the next hidden state $q_{t+1}$.\n",
    "   \n",
    "   b. Emit an observation: Based on the current state $q_t$ and the symbol emission probabilities $B$, sample the observation $o_t$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://ars.els-cdn.com/content/image/3-s2.0-B9780124077959000141-f14-09-9780124077959.jpg' />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baum-Welch algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- unsupervised learning to train HMM model\n",
    "\n",
    "- objective: Expectation-Maximization. \n",
    "\n",
    "   estimate HMM parameters $\\hat \\mu=(\\hat A, \\hat B, \\hat \\Pi)$ by maximizing likelihood of observed sequence $O=\\{o_1, o_2, ..., o_T\\}$, given the initial guess of the parameters $\\mu_0=(A, B, \\Pi)$\n",
    "\n",
    "   $$\n",
    "   \\mu=\\arg\\max_{\\mu}\\log P(O|\\mu)= \\log \\sum_Q P(O, Q | \\lambda)\n",
    "   $$\n",
    "\n",
    "   The difficulty in directly maximizing this expression comes from the summation over $Q= {q_1, q_2, ..., q_T}$ inside the logarithm, which makes the problem of direct maximization intractable.\n",
    "\n",
    "   Baum-Welch (EM) algorithm overcomes this difficulty by iteratively performing E-step and M-step"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm\n",
    "\n",
    "1. initialization: Initialize the transition probabilities, emission probabilities, and initial state probabilities.\n",
    "\n",
    "2. repeat until the parameters convergence:\n",
    "\n",
    "   - Expectation (E-step): Compute the expected count of transitions and emissions using the forward-backward algorithm.\n",
    "\n",
    "   - Maximization (M-step):  Update the transition probabilities, emission probabilities, and initial state probabilities based on the expected counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# psudo code\n",
    "initialize A, B and pi to some initial values\n",
    "repeat until convergence:\n",
    "    compute alpha and beta using the forward-backward algorithm\n",
    "    for each state i:\n",
    "        pi[i] = gamma[1][i]\n",
    "        for each state j:\n",
    "            A[i][j] = expected number of transitions from state i to state j / expected number of transitions from state i\n",
    "            for each observation vk in V:\n",
    "                B[i][vk] = expected number of times in state i and observing vk / expected number of times in state i\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\gamma[t][i] = P(q_t = i | O, \\mu)$ is posterior probability of being in state i at time t given the observation sequence and the model parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objective: find state sequence $\\mathcal{Q}$ given observation sequence $O$ and HMM model $\\mu$\n",
    "\n",
    "$$\n",
    "Q=\\arg\\max_{Q}P(Q|O, \\mu)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dynamic programming Algorithm\n",
    "\n",
    "1. Initialization: Initialize the maximum probability path $v_1$ and the corresponding backpointer $b$ at the initial state. \n",
    "\n",
    "    $$\n",
    "    v_1(i) = \\pi_i B_i(o_1) \\quad \\forall i: 1 \\leq i \\leq N\\\\[1em]\n",
    "    B_1(i)=0 \\quad \\forall i: 1 \\leq i \\leq N\n",
    "    $$\n",
    "\n",
    "2. Recursion: For each state at each subsequent time step $t (2 < t \\leq T)$, compute the maximum probability path $v_t$ that ends at this state, and update the backpointer $B_t$.\n",
    "   \n",
    "   $$\n",
    "   v_t(i) = \\max_{1 \\leq j \\leq N} v_{t-1}(j) A_{ji} B_i(o_t) \\quad 1 \\leq i \\leq N \\\\[1em]\n",
    "   B_t(i) = \\arg\\max_{1 \\leq j \\leq N} v_{t-1}(i) A_{ji}B_i(o_t) \\quad 1 \\leq i \\leq N\n",
    "   $$\n",
    "\n",
    "3. Termination: Find the state with the maximum probability at the final time step $T$, and trace back the path using the backpointers to find the most likely sequence of states.\n",
    "\n",
    "   Best score: $P^* = \\max_{1 \\leq i \\leq N} v_T(i)$\n",
    "\n",
    "   Start of backtrace: $q_T^* = \\arg\\max_{1 \\leq i \\leq N} v_T(i)$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation:\n",
    "\n",
    "- A: state transition probability matrix. shape (N, N)\n",
    "    A[i][j]: probability of transitioning from state i to state j\n",
    "\n",
    "- B: emission probability matrix. shape (N, |V|)\n",
    "\n",
    "- pi: initial state probability distribution. pi[i] is the probability of starting in state i\n",
    "\n",
    "- O: sequence of observations. O[t] is the observation at time t.\n",
    "\n",
    "- v:  Viterbi trellis matrix. shape (N, T)\n",
    "\n",
    "    v[t][i] : probability of the most probable state sequence responsible for the first t observations that has i as its final state. \n",
    "\n",
    "- backpointer: a 2D array that keeps track of the state with the highest probability at each step. \n",
    "            used to reconstruct the most probable state sequence once the algorithm has finished.\n",
    "\n",
    "- bestpathprob: probability of the most probable state sequence.\n",
    "\n",
    "- bestpathpointer: state which ends the most probable state sequence.\n",
    "\n",
    "- bestpath: most probable state sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudocode\n",
    "\n",
    "```markdown\n",
    "initialize v[1][i] = pi[i] * B[i][O[1]] for all i\n",
    "initialize backpointer[1][i] = 0 for all i\n",
    "for t from 2 to T:\n",
    "    for i from 1 to N:\n",
    "        v[t][i] = max over all j (v[t-1][j] * A[j][i]) * B[i][O[t]]\n",
    "        backpointer[t][i] = argmax over all j (v[t-1][j] * A[j][i])\n",
    "\n",
    "bestpathprob = max over all i (v[T][i])\n",
    "bestpathpointer = argmax over all i (v[T][i])\n",
    "\n",
    "bestpath = the path ending in bestpathpointer\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trellis is a type of data structure used for dynamic programming. \n",
    "\n",
    "visualized as a grid or a graph, but represented as a 2D array in implementation.\n",
    "\n",
    "Consider a HMM with three hidden states (H1, H2, H3) and three observations (O1, O2, O3). \n",
    "\n",
    "The Viterbi trellis for this case might look something like this:\n",
    "\n",
    "```markdown\n",
    "        H1  ---->  H1 ----> H1\n",
    "        |         |        |\n",
    "        v         v        v\n",
    "        H2  ---->  H2 ----> H2\n",
    "        |         |        |\n",
    "        v         v        v\n",
    "        H3  ---->  H3 ----> H3\n",
    "\n",
    "        |         |        |\n",
    "        v         v        v\n",
    "        O1        O2       O3\n",
    "```\n",
    "\n",
    "The goal of the Viterbi algorithm is to find the most probable path through the hidden states (H1, H2, H3) that leads to the observed sequence (O1, O2, O3).\n",
    "\n",
    "For instance, the most probable path might be H1 -> H2 -> H3, meaning that observation O1 was most likely generated when the system was in state H1, O2 when the system was in state H2, and so on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward and backward algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward Algorithm:**\n",
    "\n",
    "1. Initialization: initialize forward probability at first time step for each possible state $i\\in \\{N\\}$\n",
    "\n",
    "    $$\\alpha_1(i) = \\pi_i \\cdot B_i(O_1) \\quad \\forall i$$\n",
    "\n",
    "2. Recursion: Starts from the beginning of sequence, moves forward in time, computing the forward probabilities at each time step for each possible state.\n",
    "\n",
    "    $$\\alpha_t(i) = B_i(O_t)\\left(\\sum_{j=1}^N \\alpha_{t-1}(j) \\cdot A_{ji}\\right)   \\quad \\text{for } t=2 \\text{ to } T \\text{ and } \\forall i$$\n",
    "\n",
    "\n",
    "**Backward Algorithm:**\n",
    "\n",
    "1. Initialization: initialize backward probability at final time step for each possible state $i\\in \\{N\\}$ to be 1 \n",
    "\n",
    "    $$\\beta_T(i) = 1 \\quad \\forall i$$\n",
    "\n",
    "2. Recursion: Starts from the end of the sequence and moves backward in time, computing the backward probabilities at each time step for each possible state.\n",
    "\n",
    "    $$\\beta_t(i) = \\sum_{j=1}^N A_{ij} \\cdot B_j(O_{t+1}) \\cdot \\beta_{t+1}(j) \\quad \\text{for } t=T-1 \\text{ to } 1 \\text{ and } \\forall i$$\n",
    "\n",
    "**Combine**: compute the posterior probabilities for the hidden states $i$ at each time step $t$ given the observed sequence $O$ by forward probabilities ($\\alpha$) and backward probabilities ($\\beta$).\n",
    "\n",
    "$$\n",
    "p(q_t = i | O) = \\frac{\\alpha_t(i) \\cdot \\beta_t(i)}{\\sum_{j=1}^N \\alpha_t(j) \\cdot \\beta_t(j)}\n",
    "$$\n",
    "\n",
    "The denominator normalizes the probability, ensuring that the sum of the posterior probabilities over all states at time t is equal to 1. It sums over the joint probabilities of the observation sequence $O$ and all possible hidden states $j$ at time step $t$. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation:\n",
    "\n",
    "- $\\alpha$: forward probability matrix, contains the joint probabilities of observing the partial sequence up to each time step and being in each state at that time step\n",
    "\n",
    "    $\\alpha_t(i)$: probability of being in state i at time t, given the observed sequence **up to time t** $O(1:t)$ and the Hidden Markov Model parameters.\n",
    "\n",
    "- $\\beta$: backward probability matrix, contains the conditional probabilities of the ending partial sequence given each state at each time step.\n",
    "\n",
    "    $\\beta_t(i)$: probability of the observed sequence from time $t+1$ to the end $O(t+1:T)$, given that system is in state $i$ at time $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# forward pass\n",
    "initialize alpha[1][i] = pi[i] * B[i][O[1]] for all i\n",
    "for t from 2 to T:\n",
    "    for i from 1 to N:\n",
    "        alpha[t][i] = (sum over all j (alpha[t-1][j] * A[j][i])) * B[i][O[t]]\n",
    "\n",
    "# backward pass\n",
    "initialize beta[T][i] = 1 for all i\n",
    "for t from T-1 down to 1:\n",
    "    for i from 1 to N:\n",
    "        beta[t][i] = sum over all j (A[i][j] * B[j][O[t+1]] * beta[t+1][j])\n",
    "\n",
    "return: alpha, beta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLE (Maximum Likelihood Estimation) can be used to estimate the parameters of an HMM when the dataset is fully labeled, meaning that both the observation sequences and the corresponding hidden state sequences are known. \n",
    "\n",
    "the estimated parameters A and B can then be used as input for the Viterbi and Forward-Backward algorithms.\n",
    "\n",
    "- Estimate the state transition probabilities\n",
    "\n",
    "    $$\n",
    "    A_{ij} = \\frac{\\text{Count}(q_t = s_i, q_{t+1} = s_j)}{\\text{Count}(q_t = s_i)}\n",
    "    $$\n",
    "\n",
    "- Estimate the observation probabilities\n",
    "\n",
    "    $$\n",
    "    B_{ij} = \\frac{\\text{Count}(q_t = s_i, o_t = w_j)}{\\text{Count}(q_t = s_i)}\n",
    "    $$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
