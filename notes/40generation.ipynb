{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# natural language generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP = Natural Language Understanding (NLU) + Natural Language Generation (NLG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**text generation task**: \n",
    "\n",
    "input: $\\{w_{1:k}\\} \\sim p_∗$, a text sequence/prefix sampling from true distribution. \n",
    "\n",
    "output: ${\\hat w}_{k+1:T} \\sim p_{\\theta}(\\cdot|\\{w_{1:k}\\} )$, a continuation decoded by language model $p_{\\theta}$\n",
    "\n",
    "goal: resulting completion $\\hat x = (w_1, . . . , w_k, w_{k+1}, . . . , w_T)$ resembles a sample from true distribution $p_∗$\n",
    "\n",
    "Example task:\n",
    "\n",
    "- language modeling: k = 0\n",
    "\n",
    "- dialogue system: input is a dialogue history and output is a next utterance.\n",
    "\n",
    "decoding algorithm: Given language model $p_{\\theta}$ and a prefix, finding the optimal continuation is intractable, so in practice deterministic or stochastic decoding algorithms are used to generate continuations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## application"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close-ended generatition:\n",
    "\n",
    "- machine translation\n",
    "\n",
    "- summarization\n",
    "\n",
    "- table-to-text\n",
    "\n",
    "- task-driven chat\n",
    "\n",
    "- reading comprehension QA\n",
    "\n",
    "open-ended generation:\n",
    "\n",
    "- ChitChat\n",
    "\n",
    "- story/poem generation\n",
    "\n",
    "- image description\n",
    "\n",
    "- open-domain QA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model: encoder-decoder or decoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training objective: language modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**language modeling**: model a probability distribution $p_∗(x)$ over variable-length text sequences $x = (w_1, ... , w_T)$ composed of tokens from a vocabulary, $w_t \\in \\mathcal{V}$. \n",
    "\n",
    "We approximate true distribution $p_∗$ by a neural language model $p_{\\theta}$ parameterized by $\\theta$\n",
    "\n",
    "$$p_{\\theta}(x) = \\prod^T_{t=1} p_{\\theta}(w_t|w_{<t})$$\n",
    "\n",
    "training objective: **Maximum Likelihood**: find parameters $\\theta$ that maximize log likelihood of next token $w_t$ given preceding context words $\\{w_{< t}\\}$ in a finite set of samples $\\mathcal{D}$ from true distribution $p_∗$\n",
    "\n",
    "$$\n",
    "L_{MLE}=-\\sum_{i=1}^{|\\mathcal{D}|}\\sum_{t=1}^T \\log P_{\\theta}(w_t^{(i)}|\\{w_{< t}\\}^{(i)})=-\\sum_{i=1}^{|\\mathcal{D}|}\\sum_{t=1}^T \\log \\frac{\\exp(S_w)}{\\sum_{w' \\in V} \\exp(S_{w'})}\n",
    "$$\n",
    "\n",
    "$S=f(\\{y_{< t}\\}) \\in \\mathbb{R}^{V}$ is logit vectors output from model $p_{\\theta}$ that contains confidence score for each token in vocabulary. take softmax, it becomes probability distribution\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neural text degeneration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text degeneration: generated text is nonsensical, repetitive, or inconsistent, especially open-ended task\n",
    "\n",
    "some Phenomena:\n",
    "\n",
    "- **Repetition**: Models repeat phrases or sentences that were previously generated.\n",
    "\n",
    "- **Overuse of Common Phrases**: generated text sound generic and dull, Lack of Diversity.\n",
    "\n",
    "- Inconsistency: e.g., describe the weather as sunny and then, a few sentences later, mention that it's raining.\n",
    "\n",
    "- Nonsensical Text: model generates text that is syntactically correct but semantically meaningless.\n",
    "\n",
    "reason: \n",
    "\n",
    "- trained by maximum likelihood objective that focuses on optimizing next-token conditional distributions\n",
    "\n",
    "- deterministic decoding.\n",
    "\n",
    "- exposure bias: discrepancy between the training and inference stages of a model. \n",
    "\n",
    "    training: the model is \"exposed\" to the true data distribution because it is fed the ground-truth previous tokens. \n",
    "    \n",
    "    inference: the model generates text autoregressively, using its own previous outputs as inputs for future predictions. If these predictions are wrong, they can't recover from their own bad samples, lead to error propagation, where one mistake leads to subsequent errors in the generated text.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution of repetition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new training objective: \n",
    "\n",
    "[token-level unlikelihood (Welleck et al., 2020)](https://arxiv.org/pdf/1908.04319.pdf): MLE + unlikelihood loss, penalize repeat and frequent tokens by unlikelihood loss\n",
    "\n",
    "$$\n",
    "L_{t}(p_{\\theta}(\\cdot|w_{<t}), C_{t}) = - \\underbrace{\\log p_{\\theta}(w_{t}|w_{<t})}_{likelihood}- \\alpha \\underbrace{\\sum_{c \\in C_{t}} \\log(1 - p_{\\theta}(c|w_{<t}))}_{\\text{unlikelihood}} \n",
    "$$\n",
    "  \n",
    "$C_t = \\{w_1, ..., w_{t-1}\\}$ : Set of negative candidates defined as the previous context tokens\n",
    "\n",
    "- coverage loss (See et al., 2017): penalizes if model attends to the same source words repeatedly (over-translation) or ignores certain source words (under-translation).\n",
    "\n",
    "- contrastive decoding (Li et al, 2022): find the string $x$ that difference between likelihoods under the large language model and the smaller one.  encourages the generation of text that is likely under the large language model but unlikely under the small language model.\n",
    "\n",
    "    $$\\max \\log P_{largeLM} (x) – \\log P_{smallLM} (x)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stochastic decoding algorithm\n",
    "\n",
    "- temperature: can be tuned for both beam search and sampling. apply a temperature hyperparameter $\\tau$ to the softmax to rebalance.\n",
    "\n",
    "    $$\n",
    "    P_{\\theta}(w_t^{(i)}|\\{w_{< t}\\}^{(i)})=\\frac{\\exp(S_w/\\tau)}{\\sum_{w' \\in V} \\exp(S_{w'}/\\tau)}\n",
    "    $$\n",
    "\n",
    "    $\\tau > 1$: $P$ becomes more uniform, More diverse output\n",
    "\n",
    "    $\\tau <> 1$: $P$ becomes more peaky, less diverse output\n",
    "\n",
    "- Typical Sampling (Meister et al. 2022): Reweights the score based on the entropy of the distribution.\n",
    "\n",
    "- Epsilon Sampling (Hewitt et al. 2022): Set a threshold for lower bounding valid probabilities.\n",
    "\n",
    "- reranking: Define a score to approximate quality of sequences (e.g., style, discourse, entailment, logical consistency) and re-rank a bunch of decoded sequences by this score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution of exposure bias "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scheduled sampling (Bengio et al., 2015): teacher forcing: With some probability p, decode a token and feed that as the next input, rather than the gold token and Increase p over the course of training\n",
    "\n",
    "- Dataset Aggregation (DAgger; Ross et al., 2011): At various intervals during training, Add generated sequences to training set as additional examples\n",
    "\n",
    "- retrieval augmentation  (Guu, Hashimoto, et al., 2018)\n",
    "\n",
    "    input: a prompt (e.g., dialogue query)\n",
    "\n",
    "    output: human-like edited sequence (e.g., dialogue responses)\n",
    "\n",
    "    two-step process:\n",
    "\n",
    "    Retrieve: The model queries a prototype database of human-written text to find a sequence that is relevant to the input.\n",
    "\n",
    "    Edit: The model then modifies the retrieved sequence to better fit the context of the input. This could involve adding, removing, or changing words or phrases in the retrieved text.\n",
    "\n",
    "\n",
    "- Reinforcement Learning: cast your text generation model as a Markov decision process. Learn behaviors by rewarding the model when it exhibits them\n",
    "\n",
    "    reward function: 1. use evaluation metrics, e.g., BLEU for machine translation, ROUGE for summarization, CIDEr and SPIDEr for image captioning. 2. learn a reward function of human preference (RLHF)\n",
    "\n",
    "    rewardable behaviors: formality, politeness, consistency, sentence simplicity\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoding algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model generates probability distributions over all possible output tokens at each time step\n",
    "\n",
    "decoding algorithms $g$ use these probabilities to select the most likely output sequences. \n",
    "\n",
    "$$\n",
    "\\hat w_t = g(P(w_t |\\{w_{< t}\\}))\n",
    "$$\n",
    "\n",
    "can be divided to deterministic (greedy search, beam search) and stochastic (various sampling methods)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Deterministic or Stochastic</th>\n",
    "            <th>Algorithm</th>\n",
    "            <th>Description</th>\n",
    "            <th>Pros</th>\n",
    "            <th>Cons</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td rowspan=\"3\">Deterministic</td>\n",
    "            <td>Greedy Search</td>\n",
    "            <td>Select the most probable token at each step</td>\n",
    "            <td>Computationally efficient</td>\n",
    "            <td>Suboptimal; can get stuck in local optima</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Beam Search</td>\n",
    "            <td>Explore k hypotheses in parallel</td>\n",
    "            <td>Better quality sequences; more efficient than exhaustive search</td>\n",
    "            <td>Can suffer from duplicate hypotheses; higher computational cost than greedy search</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Length-Normalized Search</td>\n",
    "            <td>Normalize sequence probability by length</td>\n",
    "            <td>Generates sequences of desirable length</td>\n",
    "            <td>Can be sensitive to the normalization factor</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"3\">Stochastic</td>\n",
    "            <td>Top-k Sampling</td>\n",
    "            <td>Sample from the top k (k=50) most probable tokens</td>\n",
    "            <td>More diverse sequences; introduces randomness</td>\n",
    "            <td>Risk of generating incoherent sequences</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Top-p (Nucleus) Sampling</td>\n",
    "            <td>Sample tokens based on top p cumulative probability</td>\n",
    "            <td>Dynamic token selection; more diverse sequences</td>\n",
    "            <td>Risk of generating incoherent sequences; higher computational cost than greedy search</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Temperature-Scaled Sampling</td>\n",
    "            <td>Modify token probabilities using temperature</td>\n",
    "            <td>Control over diversity and randomness</td>\n",
    "            <td>Requires tuning the temperature parameter; risk of generating incoherent sequences</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beam search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- beam search is a greedy algorithm widely used in sequence generation tasks to find the most likely output sequence in a computationally efficient manner.\n",
    "\n",
    "- Beam search provides a trade-off between the computational cost and search quality. \n",
    "\n",
    "- hyperparameter: beam size (K: number of possible sequences)\n",
    "\n",
    "    A larger beam width increases the likelihood of finding a better solution but requires more computational resources. \n",
    "\n",
    "**Algorithm**\n",
    "\n",
    "1. Initialize the beam with the [BOS]\n",
    "\n",
    "2. At each time step\n",
    "\n",
    "    expand the sequences in the beam by considering all possible next tokens.\n",
    "\n",
    "    Score each expanded sequence using a scoring function.\n",
    "\n",
    "    Keep only the top K sequences (where K is the beam width) based on their scores and discard the rest.\n",
    "\n",
    "3. Repeat steps 2 until the [EOS] is reached for all sequences in the beam.\n",
    "\n",
    "4. Choose the sequence with the highest score as the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://d2l.ai/_images/beam-search.svg' />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | Content Overlap Metrics | Model-Based Metrics | Human Evaluation |\n",
    "|---|---|---|---|\n",
    "| Description |lexical similarity between generated and gold-standard | semantic similarity between generated and gold-standard <br>computed by pretrained word/sentence embeddings | Human judgement of various dimensions (fluency, coherence/consistency, factuality and correctness, commonsense, style/formality, grammaticality, typicality, redundancy) |\n",
    "| Example Metrics | BLEU, ROUGE, METEOR, CIDEr | Word-level: Vector Similarity, Word Mover’s Distance, BERTSCORE<br>Sentence-level: Sentence Movers Similarity, BLEURT, MAUVE | ADEM, HUSE |\n",
    "| Pros | Simple, widely used, closed-ended tasks| open-ended tasks | gold standard |\n",
    "| Cons | open-ended tasks| Require pretrained model for embeddings, fixed embeddings may not capture all nuances | inconsistent, unreproducible, time-consuming and expensive |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it's important to remember that evaluation metrics are just tools, and they may not capture all aspects of text quality. \n",
    "\n",
    "researchers should examine the model's outputs themselves and releasing large samples of these outputs for the community to review."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
