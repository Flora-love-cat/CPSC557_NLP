# CPSC 557 Natural Language Processing

Introduction to NLP: 

- history: symbolic, statistic, neural network

- application and task

- analysis unit

- workflow

- research and conference


Introduction to linguistics

- subfields: grammar (morphology, syntax), semantics (lexical, combinational, distributional)

- ambiguity

language model

- deterministic: 

    - formal grammar and automata
    
        - context-free grammar: X-bar theory, head-driven phrase structure grammar, probabilistic context-free grammar (PCFG)

        - midly context-sensitive grammar: tree adjoining grammar (TAG), combinatory categorical grammar (CCG)


- probablistic:

    - statistical: Frequentist (n-gram, HMM), Bayesian (Noisy channel, LDA, Naive Bayes)

    - Neural network

        - recurrent NN: SRN, LSTM, GRU

        - transformer: attention, GPT, BERT, SpanBERT, T5

        - Recursive NN

        - CNN


text proprocessing

feature representation

- word embedding: count-based (LSA), distributed (Word2Vec, GloVe, FastText), contextualized (ELMo, BERT), Multilingual (MUSE)

- document embedding: term-document matrix factorization (Bag of Words, TF-IDF)


transfer-learning

- pre-training: representation learning, language modelling, next sentence prediction, multi-task learning, denosing autoencoding, contrastive learning

- fine-tuning: prompt engineering, instruct fine-tuning

Tasks

- text similarity

- POS tagging

- semantic role labelling

- natural language inference

- sentiment analysis

- parsing

    - syntactic parsing: constituency parsing (Earley, CYK, Recursive-descent, Shift-reduce), dependency parsing (MalParser, Maximum Spanning Tree, Neural network)

    - semantic parsing: First-order logic, SQL query.

- information extraction: relation extraction, named entity recognition

- topic modelling

- disambiguation: coreference resolution

Applications

- machine translation

- Question answering

- dialogue system and ChatBot

- summarization

- generation

Interpretability

Ethnics
